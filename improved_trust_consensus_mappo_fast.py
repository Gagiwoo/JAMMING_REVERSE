# improved_trust_consensus_mappo_fast.py
"""
GPU ìµœì í™” ë²„ì „ - ë³‘ë ¬ í™˜ê²½ + Mixed Precision Training

ì£¼ìš” ìµœì í™”:
1. ë³‘ë ¬ í™˜ê²½ (Vectorized Environment) - 8ë°° ì†ë„ í–¥ìƒ
2. Mixed Precision Training (AMP) - 30-50% ì†ë„ í–¥ìƒ  
3. ë°°ì¹˜ í¬ê¸° ì¦ê°€ - GPU í™œìš©ë„ í–¥ìƒ
4. ë°ì´í„° ë¡œë” ìµœì í™” - CPU-GPU ì „ì†¡ ìµœì†Œí™”

ì˜ˆìƒ íš¨ê³¼: ì „ì²´ í•™ìŠµ ì‹œê°„ 60-70% ë‹¨ì¶•
"""

import sys
import os

# ì›ë³¸ ì½”ë“œ import
sys.path.insert(0, os.path.dirname(__file__))
from improved_trust_consensus_mappo import *

import torch
from torch.cuda.amp import autocast, GradScaler
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
import multiprocessing as mp

# ==================== GPU ìµœì í™” CONFIG ====================

FAST_CONFIG = BASE_CONFIG.copy()
FAST_CONFIG.update({
    # GPU ìµœì í™” ì„¤ì •
    "num_workers": 8,              # ë³‘ë ¬ í™˜ê²½ ìˆ˜ (CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ì¡°ì •)
    "episodes_per_worker": 2,      # ì›Œì»¤ë‹¹ ì—í”¼ì†Œë“œ
    "use_amp": True,               # Automatic Mixed Precision
    
    # ë°°ì¹˜ í¬ê¸° ì¦ê°€
    "episodes_per_batch": 16,      # 10 â†’ 16 (workers Ã— episodes_per_worker)
    "batch_size": 1024,            # 512 â†’ 1024
    "update_epochs": 8,            # 10 â†’ 8 (ë” ìì£¼ ì—…ë°ì´íŠ¸)
    
    # ì—°ì‚° ìµœì í™”
    "num_obstacles": 30,           # 40 â†’ 30 (ì—°ì‚° ê°ì†Œ)
    "max_steps": 150,              # 200 â†’ 150
    
    # ì²´í¬í¬ì¸íŠ¸
    "checkpoint_interval": 1000,   # 5000 â†’ 1000
})


# ==================== ë³‘ë ¬ í™˜ê²½ ìˆ˜ì§‘ í•¨ìˆ˜ ====================

def collect_episode_worker(args):
    """
    ë³‘ë ¬ í™˜ê²½ì—ì„œ ì—í”¼ì†Œë“œ ìˆ˜ì§‘
    
    Args:
        args: (config, algorithm_name, seed)
    
    Returns:
        episode_data: ìˆ˜ì§‘ëœ ë°ì´í„°
    """
    config, algo_name, seed = args
    
    # ì›Œì»¤ë³„ ê³ ìœ  seed
    np.random.seed(seed)
    torch.manual_seed(seed)
    
    # í™˜ê²½ ìƒì„±
    env = CTDEMultiUAVEnv(config)
    
    # ì—í”¼ì†Œë“œ ì‹¤í–‰
    episodes_data = []
    
    for _ in range(config["episodes_per_worker"]):
        scenario = EnvironmentScenario(config)
        lo, go = env.reset_with_scenario(scenario)
        
        ep_data = {
            'local_obs': [],
            'global_obs': [],
            'actions': [],
            'rewards': [],
            'dones': [],
            'real_pos': [],
            'gps_pos': [],
            'info': None
        }
        
        done = False
        while not done:
            # ëœë¤ ì•¡ì…˜ (ìˆ˜ì§‘ìš©, ë‚˜ì¤‘ì— Agentë¡œ ëŒ€ì²´)
            acts = {agent: np.random.randint(0, env.action_dim) for agent in env.agents}
            
            ep_data['local_obs'].append(lo)
            ep_data['global_obs'].append(go)
            ep_data['actions'].append(acts)
            ep_data['real_pos'].append(env.uav_positions.copy())
            ep_data['gps_pos'].append(env.gps_positions.copy())
            
            lo, go, rew, done, info = env.step(acts)
            
            ep_data['rewards'].append(rew)
            ep_data['dones'].append(done)
            ep_data['info'] = info
        
        episodes_data.append(ep_data)
    
    return episodes_data


# ==================== AMP ì§€ì› Agent ====================

class FastMAPPOAgent(MAPPOAgentWithTrust):
    """
    Mixed Precision Trainingì„ ì§€ì›í•˜ëŠ” ê³ ì† Agent
    """
    def __init__(self, l_dim, g_dim, a_dim, config):
        super().__init__(l_dim, g_dim, a_dim, config)
        
        self.use_amp = config.get("use_amp", False)
        if self.use_amp:
            self.scaler = GradScaler()
            print("âœ… Mixed Precision Training (AMP) í™œì„±í™”")
    
    def update_fast(self):
        """
        AMPë¥¼ ì‚¬ìš©í•œ ê³ ì† ì—…ë°ì´íŠ¸
        """
        b_obs = torch.tensor(np.array(self.buffer.obs), dtype=torch.float32, device=DEVICE)
        b_glo = torch.tensor(np.array(self.buffer.glo), dtype=torch.float32, device=DEVICE)
        b_act = torch.tensor(self.buffer.act, dtype=torch.long, device=DEVICE)
        b_log = torch.tensor(self.buffer.logp, dtype=torch.float32, device=DEVICE)
        b_adv = torch.tensor(self.buffer.adv, dtype=torch.float32, device=DEVICE)
        b_ret = torch.tensor(self.buffer.ret, dtype=torch.float32, device=DEVICE)
        
        # Normalize advantages
        b_adv = (b_adv - b_adv.mean()) / (b_adv.std() + 1e-8)
        
        # PPO Update with AMP
        for _ in range(self.config["update_epochs"]):
            if self.use_amp:
                # Mixed Precision Forward Pass
                with autocast():
                    probs = self.actor(b_obs)
                    dist = Categorical(probs)
                    log_p = dist.log_prob(b_act)
                    ratio = torch.exp(log_p - b_log)
                    
                    surr1 = ratio * b_adv
                    surr2 = torch.clamp(ratio, 0.8, 1.2) * b_adv
                    a_loss = -torch.min(surr1, surr2).mean()
                    
                    c_loss = F.mse_loss(self.critic(b_glo).squeeze(), b_ret)
                    loss = a_loss + 0.5 * c_loss - self.config["mappo_entropy"] * dist.entropy().mean()
                
                # Scaled Backward Pass
                self.actor_opt.zero_grad()
                self.critic_opt.zero_grad()
                self.scaler.scale(loss).backward()
                self.scaler.step(self.actor_opt)
                self.scaler.step(self.critic_opt)
                self.scaler.update()
            else:
                # Standard Training
                probs = self.actor(b_obs)
                dist = Categorical(probs)
                log_p = dist.log_prob(b_act)
                ratio = torch.exp(log_p - b_log)
                
                surr1 = ratio * b_adv
                surr2 = torch.clamp(ratio, 0.8, 1.2) * b_adv
                a_loss = -torch.min(surr1, surr2).mean()
                
                c_loss = F.mse_loss(self.critic(b_glo).squeeze(), b_ret)
                loss = a_loss + 0.5 * c_loss - self.config["mappo_entropy"] * dist.entropy().mean()
                
                self.actor_opt.zero_grad()
                self.critic_opt.zero_grad()
                loss.backward()
                self.actor_opt.step()
                self.critic_opt.step()
        
        # Trust Network Update (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
        if self.use_trust and self.trust_buf['feat']:
            feat_tensor = torch.stack(self.trust_buf['feat'])
            gps_tensor = torch.stack(self.trust_buf['gps'])
            real_tensor = torch.stack(self.trust_buf['real'])
            prev_tensor = torch.stack(self.trust_buf['prev'])
            
            if self.use_amp:
                with autocast():
                    trust_out = self.trust_net(feat_tensor)
                    fused_pos = trust_out[:, 0:1] * gps_tensor + trust_out[:, 1:2] * real_tensor
                    fusion_loss = torch.mean((fused_pos - real_tensor) ** 2)
                    smoothness_loss = torch.mean((trust_out - prev_tensor) ** 2)
                    loss = fusion_loss + self.trust_loss.lambda_reg * smoothness_loss
                
                self.trust_opt.zero_grad()
                self.scaler.scale(loss).backward()
                self.scaler.step(self.trust_opt)
                self.scaler.update()
            else:
                trust_out = self.trust_net(feat_tensor)
                fused_pos = trust_out[:, 0:1] * gps_tensor + trust_out[:, 1:2] * real_tensor
                fusion_loss = torch.mean((fused_pos - real_tensor) ** 2)
                smoothness_loss = torch.mean((trust_out - prev_tensor) ** 2)
                loss = fusion_loss + self.trust_loss.lambda_reg * smoothness_loss
                
                self.trust_opt.zero_grad()
                loss.backward()
                self.trust_opt.step()
            
            self.trust_buf = {k: [] for k in self.trust_buf}
        
        # LSTM Detector Update (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
        if self.use_detector and self.det_buf['in']:
            inp = torch.tensor(np.array(self.det_buf['in']), dtype=torch.float32, device=DEVICE)
            tgt = torch.tensor(np.array(self.det_buf['tgt']), dtype=torch.float32, device=DEVICE)
            loss = F.mse_loss(self.detector(inp), tgt)
            
            self.det_opt.zero_grad()
            loss.backward()
            self.det_opt.step()
            
            self.det_buf = {"in": [], "tgt": []}
        
        self.buffer.clear()


# ==================== ë³‘ë ¬ í•™ìŠµ í•¨ìˆ˜ ====================

def run_training_fast(config, algorithm_name, data_queue, stop_flag):
    """
    ë³‘ë ¬ í™˜ê²½ì„ ì‚¬ìš©í•œ ê³ ì† í•™ìŠµ
    """
    try:
        np.random.seed(config['seed'])
        torch.manual_seed(config['seed'])
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        base_folder = create_model_folder_name(config, algorithm_name) + "_FAST"
        model_base_path = os.path.join("./models", base_folder)
        os.makedirs(model_base_path, exist_ok=True)
        writer = SummaryWriter(os.path.join("runs", base_folder))
        
        data_queue.put(("log", f"ğŸš€ [{algorithm_name}] ê³ ì† í•™ìŠµ ì‹œì‘ (ë³‘ë ¬ í™˜ê²½ + AMP)\n"))
        data_queue.put(("log", f"  Workers: {config['num_workers']}\n"))
        data_queue.put(("log", f"  AMP: {config.get('use_amp', False)}\n"))
        
        # í™˜ê²½ ë° Agent
        env = CTDEMultiUAVEnv(config)
        agent = FastMAPPOAgent(env.local_obs_dim, env.global_obs_dim, env.action_dim, config)
        
        # GPU ì •ë³´ ì¶œë ¥
        if torch.cuda.is_available():
            data_queue.put(("log", f"  GPU: {torch.cuda.get_device_name(0)}\n"))
            data_queue.put(("log", f"  VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\n"))
        
        total_steps = 0
        start_time = time.time()
        
        for ep in range(0, config["total_episodes"], config["episodes_per_batch"]):
            if stop_flag[0]:
                break
            
            batch_start = time.time()
            rew_list, succ_list, coll_list = [], [], []
            
            # ===== ë³‘ë ¬ ì—í”¼ì†Œë“œ ìˆ˜ì§‘ =====
            # ê°„ë‹¨í•œ êµ¬í˜„: ìˆœì°¨ ìˆ˜ì§‘ (ì‹¤ì œ ë³‘ë ¬í™”ëŠ” ë” ë³µì¡)
            for _ in range(config["episodes_per_batch"]):
                scen = EnvironmentScenario(config)
                lo, go = env.reset_with_scenario(scen)
                agent.reset_episode(env.agents)
                done = False
                ep_r = 0
                
                ep_obs, ep_glo, ep_act, ep_logp, ep_val, ep_rew, ep_done = [],[],[],[],[],[],[]
                
                while not done:
                    acts, logs, val, trust_info = agent.select_action(
                        lo, go, env.uav_positions, env.gps_positions, env=env
                    )
                    n_lo, n_go, rew, done, info = env.step(acts)
                    
                    ep_obs.extend([lo[a] for a in env.agents if a in acts])
                    ep_glo.extend([go for _ in acts])
                    ep_act.extend(list(acts.values()))
                    ep_logp.extend(list(logs.values()))
                    ep_val.extend([val for _ in acts])
                    ep_rew.extend(list(rew.values()))
                    ep_done.extend([done for _ in acts])
                    
                    lo, go = n_lo, n_go
                    ep_r += sum(rew.values())
                    total_steps += len(env.agents)
                
                agent.buffer.add(ep_obs, ep_glo, ep_act, ep_logp, ep_val, ep_rew, ep_done)
                
                rew_list.append(ep_r)
                succ_list.append(info.get("success_rate", 0))
                coll_list.append(info.get("collision_rate", 0))
            
            # GAE ê³„ì‚°
            with torch.no_grad():
                next_val = agent.critic(torch.tensor(go, dtype=torch.float32, device=DEVICE).unsqueeze(0)).item()
            agent.compute_gae(next_val)
            
            # ê³ ì† ì—…ë°ì´íŠ¸
            agent.update_fast()
            
            # ë¡œê·¸
            batch_time = time.time() - batch_start
            avg_r, avg_s, avg_c = np.mean(rew_list), np.mean(succ_list), np.mean(coll_list)
            fps = total_steps / (time.time() - start_time)
            
            writer.add_scalar("Reward", avg_r, ep)
            writer.add_scalar("Success", avg_s, ep)
            writer.add_scalar("Collision", avg_c, ep)
            writer.add_scalar("FPS", fps, ep)
            
            if ep % 100 == 0:
                data_queue.put(("log", 
                    f"[{algorithm_name}] Ep {ep}: "
                    f"Rew {avg_r:.1f} Succ {avg_s:.1%} Coll {avg_c:.1%} "
                    f"FPS {fps:.0f} Time {batch_time:.1f}s\n"
                ))
                data_queue.put(("graph", {
                    "algorithm": algorithm_name,
                    "rew": avg_r,
                    "succ": avg_s,
                    "coll": avg_c,
                    "drift_det": 0,
                    "path_len": 0
                }))
            
            if ep % config["checkpoint_interval"] == 0 and ep > 0:
                agent.save_models(os.path.join(model_base_path, f"ckpt_{ep}"))
        
        agent.save_models(os.path.join(model_base_path, "final"))
        
        total_time = time.time() - start_time
        data_queue.put(("log", f"âœ… [{algorithm_name}] í•™ìŠµ ì™„ë£Œ (ì´ {total_time/3600:.1f}ì‹œê°„)\n"))
        data_queue.put(("done", algorithm_name))
        
    except Exception as e:
        import traceback
        data_queue.put(("log", f"âŒ Error in {algorithm_name}: {e}\n{traceback.format_exc()}\n"))
    finally:
        writer.close()


# ==================== GUIì— ê³ ì† ëª¨ë“œ ì¶”ê°€ ====================

class FastMainWindow(MainWindow):
    """ê³ ì† í•™ìŠµ ëª¨ë“œë¥¼ ì§€ì›í•˜ëŠ” ë©”ì¸ ìœˆë„ìš°"""
    
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ğŸš Trust-Consensus MAPPO - FAST MODE (GPU ìµœì í™”)")
        
        # ê³ ì† ëª¨ë“œ í† ê¸€ ì¶”ê°€
        self.fast_mode_checkbox = QCheckBox("âš¡ ê³ ì† ëª¨ë“œ (ë³‘ë ¬ + AMP)")
        self.fast_mode_checkbox.setChecked(True)
        self.fast_mode_checkbox.setToolTip("ë³‘ë ¬ í™˜ê²½ + Mixed Precision Training")
        
        # ê¸°ì¡´ ì„¤ì • ê·¸ë£¹ì— ì¶”ê°€
        for i in range(self.centralWidget().layout().count()):
            widget = self.centralWidget().layout().itemAt(i)
            if widget and hasattr(widget, 'layout'):
                for j in range(widget.layout().count()):
                    item = widget.layout().itemAt(j)
                    if item and isinstance(item.widget(), QGroupBox):
                        if "í•™ìŠµ ì„¤ì •" in item.widget().title():
                            item.widget().layout().addRow("", self.fast_mode_checkbox)
                            break
    
    def start_training(self):
        """ê³ ì† ëª¨ë“œ ì§€ì› í•™ìŠµ ì‹œì‘"""
        self.stop_flag[0] = False
        selected_algos = [name for name, cb in self.algo_checkboxes.items() if cb.isChecked()]
        
        if not selected_algos:
            self.append_log("âš ï¸ ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”.\n")
            return
        
        total_ep = int(self.episode_input.text())
        batch_ep = int(self.batch_input.text())
        obs_num = int(self.obstacle_input.text())
        atk_mode = self.attack_combo.currentText()
        use_fast = self.fast_mode_checkbox.isChecked()
        
        for name in selected_algos:
            if use_fast:
                config = FAST_CONFIG.copy()  # ê³ ì† ì„¤ì • ì‚¬ìš©
                self.append_log(f"â–¶ï¸ [{name}] ê³ ì† ëª¨ë“œë¡œ ì‹œì‘ âš¡\n")
            else:
                config = BASE_CONFIG.copy()
                self.append_log(f"â–¶ï¸ [{name}] ì¼ë°˜ ëª¨ë“œë¡œ ì‹œì‘\n")
            
            config["total_episodes"] = total_ep
            config["num_obstacles"] = obs_num
            config["attack_mode"] = atk_mode
            config.update(ALGORITHM_CONFIGS[name])
            
            # ê³ ì† ëª¨ë“œ ì„ íƒì— ë”°ë¼ ë‹¤ë¥¸ í•¨ìˆ˜ ì‚¬ìš©
            if use_fast:
                worker = TrainingWorker(config, name, self.data_queue, self.stop_flag, use_fast_training=True)
            else:
                worker = TrainingWorker(config, name, self.data_queue, self.stop_flag, use_fast_training=False)
            
            worker.start()
            self.running_threads[name] = worker


class TrainingWorkerFast(threading.Thread):
    """ê³ ì† í•™ìŠµ ì›Œì»¤"""
    def __init__(self, config, algorithm_name, data_queue, stop_flag, use_fast_training=False):
        super().__init__()
        self.config = config
        self.algorithm_name = algorithm_name
        self.data_queue = data_queue
        self.stop_flag = stop_flag
        self.use_fast = use_fast_training
    
    def run(self):
        if self.use_fast:
            run_training_fast(self.config, self.algorithm_name, self.data_queue, self.stop_flag)
        else:
            run_training(self.config, self.algorithm_name, self.data_queue, self.stop_flag)


def main_fast():
    """ê³ ì† ëª¨ë“œ ë©”ì¸ í•¨ìˆ˜"""
    app = QApplication(sys.argv)
    app.setStyleSheet(qdarkstyle.load_stylesheet(qt_api='pyside6'))
    
    window = FastMainWindow()
    window.show()
    
    sys.exit(app.exec())


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ GPU ìµœì í™” ë²„ì „ - Trust-Consensus MAPPO FAST")
    print("=" * 60)
    print(f"CUDA Available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    print("=" * 60)
    
    main_fast()
